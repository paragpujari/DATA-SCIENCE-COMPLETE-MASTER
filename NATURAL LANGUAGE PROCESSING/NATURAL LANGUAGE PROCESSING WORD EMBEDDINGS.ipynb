{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the necessary libraries\n",
    "from tensorflow.keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = ['the glass of milk',\n",
    "     'the glass of juice',\n",
    "     'the cup of tea',\n",
    "    'I am a good boy',\n",
    "     'I am a good developer',\n",
    "     'understand the meaning of words',\n",
    "     'your videos are good',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the glass of milk', 'the glass of juice', 'the cup of tea', 'I am a good boy', 'I am a good developer', 'understand the meaning of words', 'your videos are good']\n"
     ]
    }
   ],
   "source": [
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary size\n",
    "voc_size = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Representation of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " It provides the index position of all the words present in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9305, 7635, 2116, 6237], [9305, 7635, 2116, 141], [9305, 8929, 2116, 9321], [1236, 2247, 754, 7051, 3755], [1236, 2247, 754, 7051, 3583], [6046, 9305, 6482, 2116, 2732], [6484, 1875, 317, 7051]]\n"
     ]
    }
   ],
   "source": [
    "onehot_representation = [ one_hot(words,voc_size) for words in sentence]\n",
    "print(onehot_representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0 9305 7635 2116 6237]\n",
      " [   0    0    0    0 9305 7635 2116  141]\n",
      " [   0    0    0    0 9305 8929 2116 9321]\n",
      " [   0    0    0 1236 2247  754 7051 3755]\n",
      " [   0    0    0 1236 2247  754 7051 3583]\n",
      " [   0    0    0 6046 9305 6482 2116 2732]\n",
      " [   0    0    0    0 6484 1875  317 7051]]\n"
     ]
    }
   ],
   "source": [
    "# To create an Embedding matrix from the onehot representation of the words\n",
    "sent_length = 8\n",
    "embedding_sequence = pad_sequences(onehot_representation, padding = 'pre', maxlen = sent_length)\n",
    "print(embedding_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the input into the embedding layer\n",
    "model = Sequential()\n",
    "# add the embedding layer\n",
    "model.add(Embedding(voc_size, 10, input_length = sent_length))\n",
    "# compile the model with 'adam' optimizer\n",
    "model.compile('adam','mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 8, 10)             100000    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100000 (390.62 KB)\n",
      "Trainable params: 100000 (390.62 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 185ms/step\n",
      "[[[ 0.00010131 -0.02468785 -0.01095946 -0.01197703  0.04227567\n",
      "   -0.03317936 -0.01047315  0.00454076  0.03931682  0.00625292]\n",
      "  [ 0.00010131 -0.02468785 -0.01095946 -0.01197703  0.04227567\n",
      "   -0.03317936 -0.01047315  0.00454076  0.03931682  0.00625292]\n",
      "  [ 0.00010131 -0.02468785 -0.01095946 -0.01197703  0.04227567\n",
      "   -0.03317936 -0.01047315  0.00454076  0.03931682  0.00625292]\n",
      "  [ 0.00010131 -0.02468785 -0.01095946 -0.01197703  0.04227567\n",
      "   -0.03317936 -0.01047315  0.00454076  0.03931682  0.00625292]\n",
      "  [-0.00483926 -0.02220302  0.00719935 -0.04338865  0.03173994\n",
      "   -0.02405405 -0.02635107  0.02894468 -0.00027215 -0.0014366 ]\n",
      "  [-0.01873233 -0.00272293  0.00105198  0.00218949 -0.0288746\n",
      "    0.02834352 -0.01328101  0.00554389  0.04593093  0.01437405]\n",
      "  [-0.03749872 -0.00343376 -0.01019546 -0.00180776 -0.00381108\n",
      "    0.0401533  -0.0130757  -0.00926391 -0.04307494 -0.00078475]\n",
      "  [ 0.02767524 -0.01392082  0.04854545  0.03666205 -0.03882828\n",
      "    0.04853204 -0.04986686 -0.02295629 -0.04807329  0.04352177]]\n",
      "\n",
      " [[ 0.00010131 -0.02468785 -0.01095946 -0.01197703  0.04227567\n",
      "   -0.03317936 -0.01047315  0.00454076  0.03931682  0.00625292]\n",
      "  [ 0.00010131 -0.02468785 -0.01095946 -0.01197703  0.04227567\n",
      "   -0.03317936 -0.01047315  0.00454076  0.03931682  0.00625292]\n",
      "  [ 0.00010131 -0.02468785 -0.01095946 -0.01197703  0.04227567\n",
      "   -0.03317936 -0.01047315  0.00454076  0.03931682  0.00625292]\n",
      "  [ 0.00010131 -0.02468785 -0.01095946 -0.01197703  0.04227567\n",
      "   -0.03317936 -0.01047315  0.00454076  0.03931682  0.00625292]\n",
      "  [-0.00483926 -0.02220302  0.00719935 -0.04338865  0.03173994\n",
      "   -0.02405405 -0.02635107  0.02894468 -0.00027215 -0.0014366 ]\n",
      "  [-0.01873233 -0.00272293  0.00105198  0.00218949 -0.0288746\n",
      "    0.02834352 -0.01328101  0.00554389  0.04593093  0.01437405]\n",
      "  [-0.03749872 -0.00343376 -0.01019546 -0.00180776 -0.00381108\n",
      "    0.0401533  -0.0130757  -0.00926391 -0.04307494 -0.00078475]\n",
      "  [ 0.03376421 -0.02032783 -0.00641849  0.01783797 -0.03060498\n",
      "    0.01306876 -0.0020205   0.01398622 -0.03067929  0.04815305]]\n",
      "\n",
      " [[ 0.00010131 -0.02468785 -0.01095946 -0.01197703  0.04227567\n",
      "   -0.03317936 -0.01047315  0.00454076  0.03931682  0.00625292]\n",
      "  [ 0.00010131 -0.02468785 -0.01095946 -0.01197703  0.04227567\n",
      "   -0.03317936 -0.01047315  0.00454076  0.03931682  0.00625292]\n",
      "  [ 0.00010131 -0.02468785 -0.01095946 -0.01197703  0.04227567\n",
      "   -0.03317936 -0.01047315  0.00454076  0.03931682  0.00625292]\n",
      "  [ 0.00010131 -0.02468785 -0.01095946 -0.01197703  0.04227567\n",
      "   -0.03317936 -0.01047315  0.00454076  0.03931682  0.00625292]\n",
      "  [-0.00483926 -0.02220302  0.00719935 -0.04338865  0.03173994\n",
      "   -0.02405405 -0.02635107  0.02894468 -0.00027215 -0.0014366 ]\n",
      "  [ 0.0344657  -0.02195877  0.00793006 -0.03420135  0.01477423\n",
      "   -0.02890545 -0.01019252 -0.04103541  0.00494098  0.04866019]\n",
      "  [-0.03749872 -0.00343376 -0.01019546 -0.00180776 -0.00381108\n",
      "    0.0401533  -0.0130757  -0.00926391 -0.04307494 -0.00078475]\n",
      "  [ 0.01282975  0.01086695 -0.04781893  0.01770366 -0.03012574\n",
      "   -0.01217068 -0.02572743  0.0340948   0.00800943 -0.03249389]]\n",
      "\n",
      " [[ 0.00010131 -0.02468785 -0.01095946 -0.01197703  0.04227567\n",
      "   -0.03317936 -0.01047315  0.00454076  0.03931682  0.00625292]\n",
      "  [ 0.00010131 -0.02468785 -0.01095946 -0.01197703  0.04227567\n",
      "   -0.03317936 -0.01047315  0.00454076  0.03931682  0.00625292]\n",
      "  [ 0.00010131 -0.02468785 -0.01095946 -0.01197703  0.04227567\n",
      "   -0.03317936 -0.01047315  0.00454076  0.03931682  0.00625292]\n",
      "  [-0.04482603  0.03887833 -0.0062151  -0.04707791 -0.03099923\n",
      "    0.03974758 -0.04839454  0.00046874  0.00969956  0.04617878]\n",
      "  [-0.04355654 -0.04737126 -0.04949027 -0.00719248 -0.02004345\n",
      "    0.04397443  0.00143067 -0.04518589  0.02940297  0.03179191]\n",
      "  [ 0.03010373 -0.02461648  0.04986849 -0.03476905 -0.01189506\n",
      "   -0.02686164  0.01118348  0.02000601  0.03481773  0.01322042]\n",
      "  [ 0.0356869  -0.04066644  0.01984037  0.04117489 -0.00621927\n",
      "   -0.01244815 -0.04355548  0.0048861  -0.03921847  0.01439244]\n",
      "  [ 0.04733405  0.00932743  0.02034623 -0.04001953  0.03561095\n",
      "    0.01390881  0.02947345  0.043387    0.02511868  0.04201001]]\n",
      "\n",
      " [[ 0.00010131 -0.02468785 -0.01095946 -0.01197703  0.04227567\n",
      "   -0.03317936 -0.01047315  0.00454076  0.03931682  0.00625292]\n",
      "  [ 0.00010131 -0.02468785 -0.01095946 -0.01197703  0.04227567\n",
      "   -0.03317936 -0.01047315  0.00454076  0.03931682  0.00625292]\n",
      "  [ 0.00010131 -0.02468785 -0.01095946 -0.01197703  0.04227567\n",
      "   -0.03317936 -0.01047315  0.00454076  0.03931682  0.00625292]\n",
      "  [-0.04482603  0.03887833 -0.0062151  -0.04707791 -0.03099923\n",
      "    0.03974758 -0.04839454  0.00046874  0.00969956  0.04617878]\n",
      "  [-0.04355654 -0.04737126 -0.04949027 -0.00719248 -0.02004345\n",
      "    0.04397443  0.00143067 -0.04518589  0.02940297  0.03179191]\n",
      "  [ 0.03010373 -0.02461648  0.04986849 -0.03476905 -0.01189506\n",
      "   -0.02686164  0.01118348  0.02000601  0.03481773  0.01322042]\n",
      "  [ 0.0356869  -0.04066644  0.01984037  0.04117489 -0.00621927\n",
      "   -0.01244815 -0.04355548  0.0048861  -0.03921847  0.01439244]\n",
      "  [-0.00917032  0.01417616 -0.04081025 -0.04437684  0.01595325\n",
      "   -0.03523671 -0.02130009  0.04587277  0.01230924 -0.04189234]]\n",
      "\n",
      " [[ 0.00010131 -0.02468785 -0.01095946 -0.01197703  0.04227567\n",
      "   -0.03317936 -0.01047315  0.00454076  0.03931682  0.00625292]\n",
      "  [ 0.00010131 -0.02468785 -0.01095946 -0.01197703  0.04227567\n",
      "   -0.03317936 -0.01047315  0.00454076  0.03931682  0.00625292]\n",
      "  [ 0.00010131 -0.02468785 -0.01095946 -0.01197703  0.04227567\n",
      "   -0.03317936 -0.01047315  0.00454076  0.03931682  0.00625292]\n",
      "  [-0.02693477 -0.01877673 -0.02171899 -0.04234166  0.04742968\n",
      "   -0.04930439  0.01160829 -0.03545349  0.01108957 -0.00527488]\n",
      "  [-0.00483926 -0.02220302  0.00719935 -0.04338865  0.03173994\n",
      "   -0.02405405 -0.02635107  0.02894468 -0.00027215 -0.0014366 ]\n",
      "  [-0.04392714  0.01168763 -0.0073131   0.02998822 -0.04751683\n",
      "    0.044656   -0.04275949  0.02643282  0.01301901  0.03151024]\n",
      "  [-0.03749872 -0.00343376 -0.01019546 -0.00180776 -0.00381108\n",
      "    0.0401533  -0.0130757  -0.00926391 -0.04307494 -0.00078475]\n",
      "  [-0.04520061  0.00738162  0.01526025 -0.016308    0.02082641\n",
      "    0.01675898 -0.02396852 -0.03030061 -0.03340067  0.01195035]]\n",
      "\n",
      " [[ 0.00010131 -0.02468785 -0.01095946 -0.01197703  0.04227567\n",
      "   -0.03317936 -0.01047315  0.00454076  0.03931682  0.00625292]\n",
      "  [ 0.00010131 -0.02468785 -0.01095946 -0.01197703  0.04227567\n",
      "   -0.03317936 -0.01047315  0.00454076  0.03931682  0.00625292]\n",
      "  [ 0.00010131 -0.02468785 -0.01095946 -0.01197703  0.04227567\n",
      "   -0.03317936 -0.01047315  0.00454076  0.03931682  0.00625292]\n",
      "  [ 0.00010131 -0.02468785 -0.01095946 -0.01197703  0.04227567\n",
      "   -0.03317936 -0.01047315  0.00454076  0.03931682  0.00625292]\n",
      "  [-0.04777832  0.04947159 -0.0496668  -0.00725764 -0.01486144\n",
      "   -0.00452195 -0.0068768   0.04495284  0.00273482 -0.0185203 ]\n",
      "  [-0.00755862 -0.02849704 -0.00870032 -0.01486244 -0.04631248\n",
      "    0.01577887 -0.02621311  0.0048663   0.02847375  0.03496584]\n",
      "  [ 0.01821083  0.03636528  0.01273808  0.03466384  0.0366899\n",
      "    0.04611779 -0.02703574 -0.04639442 -0.02113925  0.03351775]\n",
      "  [ 0.0356869  -0.04066644  0.01984037  0.04117489 -0.00621927\n",
      "   -0.01244815 -0.04355548  0.0048861  -0.03921847  0.01439244]]]\n"
     ]
    }
   ],
   "source": [
    "# Get the vectorized representation of the words\n",
    "print(model.predict(embedding_sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0 9305 7635 2116 6237]\n"
     ]
    }
   ],
   "source": [
    "print(embedding_sequence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "[[ 0.00010131 -0.02468785 -0.01095946 -0.01197703  0.04227567 -0.03317936\n",
      "  -0.01047315  0.00454076  0.03931682  0.00625292]\n",
      " [ 0.00010131 -0.02468785 -0.01095946 -0.01197703  0.04227567 -0.03317936\n",
      "  -0.01047315  0.00454076  0.03931682  0.00625292]\n",
      " [ 0.00010131 -0.02468785 -0.01095946 -0.01197703  0.04227567 -0.03317936\n",
      "  -0.01047315  0.00454076  0.03931682  0.00625292]\n",
      " [ 0.00010131 -0.02468785 -0.01095946 -0.01197703  0.04227567 -0.03317936\n",
      "  -0.01047315  0.00454076  0.03931682  0.00625292]\n",
      " [-0.00483926 -0.02220302  0.00719935 -0.04338865  0.03173994 -0.02405405\n",
      "  -0.02635107  0.02894468 -0.00027215 -0.0014366 ]\n",
      " [-0.01873233 -0.00272293  0.00105198  0.00218949 -0.0288746   0.02834352\n",
      "  -0.01328101  0.00554389  0.04593093  0.01437405]\n",
      " [-0.03749872 -0.00343376 -0.01019546 -0.00180776 -0.00381108  0.0401533\n",
      "  -0.0130757  -0.00926391 -0.04307494 -0.00078475]\n",
      " [ 0.02767524 -0.01392082  0.04854545  0.03666205 -0.03882828  0.04853204\n",
      "  -0.04986686 -0.02295629 -0.04807329  0.04352177]]\n"
     ]
    }
   ],
   "source": [
    "# Get the vectorized representation of all the onehot values in form of dimensions\n",
    "print(model.predict(embedding_sequence[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
