{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wcndQGe8MGlU"
      },
      "outputs": [],
      "source": [
        "# Importing all the necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Laoding the dataset\n",
        "data = pd.read_csv('/content/Google_Stock_Price_Train.csv')"
      ],
      "metadata": {
        "id": "zBdVx08iMjDC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gsi8EOrGMnS_",
        "outputId": "3f5be6c2-70c7-4ba1-f1dd-70bbdfc5ce8c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            Date    Open    High     Low   Close      Volume\n",
            "0       1/3/2012  325.25  332.83  324.97  663.59   7,380,500\n",
            "1       1/4/2012  331.27  333.87  329.08  666.45   5,749,400\n",
            "2       1/5/2012  329.83  330.75  326.89  657.21   6,590,300\n",
            "3       1/6/2012  328.34  328.77  323.68  648.24   5,405,900\n",
            "4       1/9/2012  322.04  322.29  309.46  620.76  11,688,800\n",
            "...          ...     ...     ...     ...     ...         ...\n",
            "1253  12/23/2016  790.90  792.74  787.28  789.91     623,400\n",
            "1254  12/27/2016  790.68  797.86  787.66  791.55     789,100\n",
            "1255  12/28/2016  793.70  794.23  783.20  785.05   1,153,800\n",
            "1256  12/29/2016  783.33  785.93  778.92  782.79     744,300\n",
            "1257  12/30/2016  782.75  782.78  770.41  771.82   1,770,000\n",
            "\n",
            "[1258 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list the first five rows of the dataset\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HHhyjWrMqI1",
        "outputId": "10e703ae-193a-4f71-923c-7f7c4b1b8692"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Date    Open    High     Low   Close      Volume\n",
            "0  1/3/2012  325.25  332.83  324.97  663.59   7,380,500\n",
            "1  1/4/2012  331.27  333.87  329.08  666.45   5,749,400\n",
            "2  1/5/2012  329.83  330.75  326.89  657.21   6,590,300\n",
            "3  1/6/2012  328.34  328.77  323.68  648.24   5,405,900\n",
            "4  1/9/2012  322.04  322.29  309.46  620.76  11,688,800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list the bottom five rows of the dataset\n",
        "print(data.tail())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3i2RhU-vMsf_",
        "outputId": "e6fab8c6-555d-4a37-e465-2e8a6f10f305"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            Date    Open    High     Low   Close     Volume\n",
            "1253  12/23/2016  790.90  792.74  787.28  789.91    623,400\n",
            "1254  12/27/2016  790.68  797.86  787.66  791.55    789,100\n",
            "1255  12/28/2016  793.70  794.23  783.20  785.05  1,153,800\n",
            "1256  12/29/2016  783.33  785.93  778.92  782.79    744,300\n",
            "1257  12/30/2016  782.75  782.78  770.41  771.82  1,770,000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# shape of the dataset\n",
        "print(data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrsbdKy1MvcN",
        "outputId": "2acb9593-9df6-4bab-b1e3-c1f93991d9ad"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1258, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To check if there are any NULL Vlaues in the dataset\n",
        "print(data.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IN_L1OnMzmB",
        "outputId": "f0d2c004-ab78-4568-f683-fa89d5390dff"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Date      0\n",
            "Open      0\n",
            "High      0\n",
            "Low       0\n",
            "Close     0\n",
            "Volume    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Observation:\n",
        "\n",
        "#From the above observation, it is clear that there are no NULL Vlaues in the datset"
      ],
      "metadata": {
        "id": "VO10MWB3M1_3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the training data set\n",
        "training_data_set = data.iloc[:,1:2].values"
      ],
      "metadata": {
        "id": "SBqjORTgM6Qw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DATA PREPROCESSING\n",
        "\n",
        "# Perform Feature Feature Scaling\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# call the object for min max scaler\n",
        "sc = MinMaxScaler(feature_range = (0,1))\n",
        "\n",
        "# performing the transformation in the training data\n",
        "training_data_scaled = sc.fit_transform(training_data_set)\n",
        "print(training_data_scaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yc1W4HE2M-Zj",
        "outputId": "338db228-2073-4c82-9dbb-f6f69018af13"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.08581368]\n",
            " [0.09701243]\n",
            " [0.09433366]\n",
            " ...\n",
            " [0.95725128]\n",
            " [0.93796041]\n",
            " [0.93688146]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a data structure with 60 timestamps and 1 output\n",
        "X_train = []\n",
        "Y_train = []\n",
        "for i in range(60, 1258):\n",
        "    X_train.append(training_data_scaled[i-60:i, 0])\n",
        "    Y_train.append(training_data_scaled[i,0])\n",
        "\n",
        "X_train, Y_train = np.array(X_train), np.array(Y_train)"
      ],
      "metadata": {
        "id": "JEtc_zTbNDZ0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshaping the dataset\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
      ],
      "metadata": {
        "id": "Suwx_L2lNHIv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BUILDING THE RNN MODEL"
      ],
      "metadata": {
        "id": "tBXWiQTTNJpa"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import the libraries for RNN Model\n",
        "import keras\n",
        "from   keras.models import Sequential\n",
        "from   keras.layers import Dense\n",
        "from   keras.layers import LSTM\n",
        "from   keras.layers import Dropout"
      ],
      "metadata": {
        "id": "LsYCI-b5NM1q"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regressor = Sequential()\n",
        "\n",
        "# add the first lstm layer and the dropout regularization\n",
        "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1],1)))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "# add the second LSTM layer and drop out regularization\n",
        "regressor.add(LSTM(units = 50, return_sequences = True))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "# add the third LSTM layer and the dropout regularization\n",
        "regressor.add(LSTM(units = 50, return_sequences = True))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "# Add the fourth LSTM layer and dropout regularization\n",
        "regressor.add(LSTM(units = 50))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "# Add the output layer\n",
        "regressor.add(Dense(units = 1))\n",
        "\n"
      ],
      "metadata": {
        "id": "q6ep0DrfNQ6J"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPILE THE RNN MODEL\n",
        "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "Vjk8G2UdNTQ7"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAIN THE RNN MODEL\n",
        "regressor.fit(X_train, Y_train, epochs = 100, batch_size = 32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTNckBQzNYUR",
        "outputId": "fc0c368a-d1d3-4063-fcc9-320976b3b84e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "38/38 [==============================] - 15s 165ms/step - loss: 0.0396 - accuracy: 0.0017\n",
            "Epoch 2/100\n",
            "38/38 [==============================] - 5s 131ms/step - loss: 0.0067 - accuracy: 0.0017\n",
            "Epoch 3/100\n",
            "38/38 [==============================] - 6s 148ms/step - loss: 0.0050 - accuracy: 0.0017\n",
            "Epoch 4/100\n",
            "38/38 [==============================] - 6s 145ms/step - loss: 0.0054 - accuracy: 0.0017\n",
            "Epoch 5/100\n",
            "38/38 [==============================] - 5s 133ms/step - loss: 0.0049 - accuracy: 0.0017\n",
            "Epoch 6/100\n",
            "38/38 [==============================] - 6s 165ms/step - loss: 0.0046 - accuracy: 0.0017\n",
            "Epoch 7/100\n",
            "38/38 [==============================] - 5s 131ms/step - loss: 0.0043 - accuracy: 0.0017\n",
            "Epoch 8/100\n",
            "38/38 [==============================] - 6s 164ms/step - loss: 0.0047 - accuracy: 0.0017\n",
            "Epoch 9/100\n",
            "38/38 [==============================] - 5s 132ms/step - loss: 0.0054 - accuracy: 0.0017\n",
            "Epoch 10/100\n",
            "38/38 [==============================] - 5s 144ms/step - loss: 0.0044 - accuracy: 0.0017\n",
            "Epoch 11/100\n",
            "38/38 [==============================] - 6s 151ms/step - loss: 0.0042 - accuracy: 0.0017\n",
            "Epoch 12/100\n",
            "38/38 [==============================] - 5s 131ms/step - loss: 0.0046 - accuracy: 0.0017\n",
            "Epoch 13/100\n",
            "38/38 [==============================] - 6s 164ms/step - loss: 0.0039 - accuracy: 0.0017\n",
            "Epoch 14/100\n",
            "38/38 [==============================] - 5s 132ms/step - loss: 0.0039 - accuracy: 0.0017\n",
            "Epoch 15/100\n",
            "38/38 [==============================] - 6s 167ms/step - loss: 0.0040 - accuracy: 0.0017\n",
            "Epoch 16/100\n",
            "38/38 [==============================] - 5s 131ms/step - loss: 0.0036 - accuracy: 0.0017\n",
            "Epoch 17/100\n",
            "38/38 [==============================] - 5s 140ms/step - loss: 0.0040 - accuracy: 0.0017\n",
            "Epoch 18/100\n",
            "38/38 [==============================] - 6s 155ms/step - loss: 0.0042 - accuracy: 0.0017\n",
            "Epoch 19/100\n",
            "38/38 [==============================] - 5s 132ms/step - loss: 0.0042 - accuracy: 0.0017\n",
            "Epoch 20/100\n",
            "38/38 [==============================] - 6s 165ms/step - loss: 0.0033 - accuracy: 0.0017\n",
            "Epoch 21/100\n",
            "38/38 [==============================] - 5s 131ms/step - loss: 0.0036 - accuracy: 0.0017\n",
            "Epoch 22/100\n",
            "38/38 [==============================] - 6s 165ms/step - loss: 0.0037 - accuracy: 0.0017\n",
            "Epoch 23/100\n",
            "38/38 [==============================] - 5s 130ms/step - loss: 0.0032 - accuracy: 0.0017\n",
            "Epoch 24/100\n",
            "38/38 [==============================] - 5s 132ms/step - loss: 0.0036 - accuracy: 0.0017\n",
            "Epoch 25/100\n",
            "38/38 [==============================] - 6s 163ms/step - loss: 0.0033 - accuracy: 0.0017\n",
            "Epoch 26/100\n",
            "38/38 [==============================] - 5s 133ms/step - loss: 0.0034 - accuracy: 0.0017\n",
            "Epoch 27/100\n",
            "38/38 [==============================] - 6s 166ms/step - loss: 0.0035 - accuracy: 0.0017\n",
            "Epoch 28/100\n",
            "38/38 [==============================] - 5s 133ms/step - loss: 0.0031 - accuracy: 0.0017\n",
            "Epoch 29/100\n",
            "38/38 [==============================] - 6s 159ms/step - loss: 0.0032 - accuracy: 0.0017\n",
            "Epoch 30/100\n",
            "38/38 [==============================] - 5s 133ms/step - loss: 0.0035 - accuracy: 0.0017\n",
            "Epoch 31/100\n",
            "38/38 [==============================] - 5s 131ms/step - loss: 0.0030 - accuracy: 0.0017\n",
            "Epoch 32/100\n",
            "38/38 [==============================] - 6s 164ms/step - loss: 0.0029 - accuracy: 0.0017\n",
            "Epoch 33/100\n",
            "38/38 [==============================] - 5s 132ms/step - loss: 0.0027 - accuracy: 0.0017\n",
            "Epoch 34/100\n",
            "38/38 [==============================] - 6s 165ms/step - loss: 0.0027 - accuracy: 0.0017\n",
            "Epoch 35/100\n",
            "38/38 [==============================] - 5s 132ms/step - loss: 0.0026 - accuracy: 0.0017\n",
            "Epoch 36/100\n",
            "38/38 [==============================] - 6s 149ms/step - loss: 0.0027 - accuracy: 0.0017\n",
            "Epoch 37/100\n",
            "38/38 [==============================] - 6s 145ms/step - loss: 0.0026 - accuracy: 0.0017\n",
            "Epoch 38/100\n",
            "38/38 [==============================] - 5s 132ms/step - loss: 0.0031 - accuracy: 0.0017\n",
            "Epoch 39/100\n",
            "38/38 [==============================] - 6s 165ms/step - loss: 0.0027 - accuracy: 0.0017\n",
            "Epoch 40/100\n",
            "38/38 [==============================] - 5s 133ms/step - loss: 0.0027 - accuracy: 0.0017\n",
            "Epoch 41/100\n",
            "38/38 [==============================] - 6s 167ms/step - loss: 0.0026 - accuracy: 0.0017\n",
            "Epoch 42/100\n",
            "38/38 [==============================] - 5s 133ms/step - loss: 0.0027 - accuracy: 0.0017\n",
            "Epoch 43/100\n",
            "38/38 [==============================] - 6s 147ms/step - loss: 0.0028 - accuracy: 0.0017\n",
            "Epoch 44/100\n",
            "38/38 [==============================] - 6s 149ms/step - loss: 0.0025 - accuracy: 0.0017\n",
            "Epoch 45/100\n",
            "38/38 [==============================] - 5s 132ms/step - loss: 0.0026 - accuracy: 0.0017\n",
            "Epoch 46/100\n",
            "38/38 [==============================] - 6s 166ms/step - loss: 0.0024 - accuracy: 0.0017\n",
            "Epoch 47/100\n",
            "38/38 [==============================] - 5s 132ms/step - loss: 0.0027 - accuracy: 0.0017\n",
            "Epoch 48/100\n",
            "38/38 [==============================] - 6s 167ms/step - loss: 0.0024 - accuracy: 0.0017\n",
            "Epoch 49/100\n",
            "38/38 [==============================] - 5s 132ms/step - loss: 0.0023 - accuracy: 0.0017\n",
            "Epoch 50/100\n",
            "38/38 [==============================] - 5s 141ms/step - loss: 0.0027 - accuracy: 0.0017\n",
            "Epoch 51/100\n",
            "38/38 [==============================] - 6s 153ms/step - loss: 0.0024 - accuracy: 0.0017\n",
            "Epoch 52/100\n",
            "38/38 [==============================] - 5s 131ms/step - loss: 0.0025 - accuracy: 0.0017\n",
            "Epoch 53/100\n",
            "38/38 [==============================] - 6s 166ms/step - loss: 0.0025 - accuracy: 0.0017\n",
            "Epoch 54/100\n",
            "38/38 [==============================] - 5s 132ms/step - loss: 0.0022 - accuracy: 0.0017\n",
            "Epoch 55/100\n",
            "38/38 [==============================] - 6s 165ms/step - loss: 0.0025 - accuracy: 0.0017\n",
            "Epoch 56/100\n",
            "38/38 [==============================] - 5s 131ms/step - loss: 0.0023 - accuracy: 0.0017\n",
            "Epoch 57/100\n",
            "38/38 [==============================] - 5s 135ms/step - loss: 0.0024 - accuracy: 0.0017\n",
            "Epoch 58/100\n",
            "38/38 [==============================] - 6s 159ms/step - loss: 0.0021 - accuracy: 0.0017\n",
            "Epoch 59/100\n",
            "38/38 [==============================] - 5s 130ms/step - loss: 0.0021 - accuracy: 0.0017\n",
            "Epoch 60/100\n",
            "38/38 [==============================] - 6s 166ms/step - loss: 0.0022 - accuracy: 0.0017\n",
            "Epoch 61/100\n",
            "38/38 [==============================] - 5s 132ms/step - loss: 0.0023 - accuracy: 0.0017\n",
            "Epoch 62/100\n",
            "38/38 [==============================] - 6s 155ms/step - loss: 0.0022 - accuracy: 0.0017\n",
            "Epoch 63/100\n",
            "38/38 [==============================] - 5s 137ms/step - loss: 0.0021 - accuracy: 0.0017\n",
            "Epoch 64/100\n",
            "38/38 [==============================] - 5s 130ms/step - loss: 0.0018 - accuracy: 0.0017\n",
            "Epoch 65/100\n",
            "38/38 [==============================] - 6s 164ms/step - loss: 0.0020 - accuracy: 0.0017\n",
            "Epoch 66/100\n",
            "38/38 [==============================] - 5s 130ms/step - loss: 0.0019 - accuracy: 0.0017\n",
            "Epoch 67/100\n",
            "38/38 [==============================] - 6s 166ms/step - loss: 0.0018 - accuracy: 0.0017\n",
            "Epoch 68/100\n",
            "38/38 [==============================] - 5s 132ms/step - loss: 0.0018 - accuracy: 0.0017\n",
            "Epoch 69/100\n",
            "38/38 [==============================] - 5s 142ms/step - loss: 0.0019 - accuracy: 0.0017\n",
            "Epoch 70/100\n",
            "38/38 [==============================] - 6s 151ms/step - loss: 0.0017 - accuracy: 0.0017\n",
            "Epoch 71/100\n",
            "38/38 [==============================] - 5s 131ms/step - loss: 0.0018 - accuracy: 0.0017\n",
            "Epoch 72/100\n",
            "38/38 [==============================] - 6s 164ms/step - loss: 0.0017 - accuracy: 0.0017\n",
            "Epoch 73/100\n",
            "38/38 [==============================] - 5s 132ms/step - loss: 0.0020 - accuracy: 0.0017\n",
            "Epoch 74/100\n",
            "38/38 [==============================] - 6s 165ms/step - loss: 0.0018 - accuracy: 0.0017\n",
            "Epoch 75/100\n",
            "38/38 [==============================] - 5s 131ms/step - loss: 0.0018 - accuracy: 0.0017\n",
            "Epoch 76/100\n",
            "38/38 [==============================] - 5s 135ms/step - loss: 0.0018 - accuracy: 0.0017\n",
            "Epoch 77/100\n",
            "38/38 [==============================] - 6s 157ms/step - loss: 0.0015 - accuracy: 0.0017\n",
            "Epoch 78/100\n",
            "38/38 [==============================] - 5s 133ms/step - loss: 0.0017 - accuracy: 0.0017\n",
            "Epoch 79/100\n",
            "38/38 [==============================] - 6s 164ms/step - loss: 0.0016 - accuracy: 0.0017\n",
            "Epoch 80/100\n",
            "38/38 [==============================] - 5s 132ms/step - loss: 0.0016 - accuracy: 0.0017\n",
            "Epoch 81/100\n",
            "38/38 [==============================] - 6s 164ms/step - loss: 0.0017 - accuracy: 0.0017\n",
            "Epoch 82/100\n",
            "38/38 [==============================] - 5s 132ms/step - loss: 0.0017 - accuracy: 0.0017\n",
            "Epoch 83/100\n",
            "38/38 [==============================] - 5s 131ms/step - loss: 0.0019 - accuracy: 0.0017\n",
            "Epoch 84/100\n",
            "38/38 [==============================] - 6s 165ms/step - loss: 0.0019 - accuracy: 0.0017\n",
            "Epoch 85/100\n",
            "38/38 [==============================] - 5s 130ms/step - loss: 0.0020 - accuracy: 0.0017\n",
            "Epoch 86/100\n",
            "38/38 [==============================] - 6s 164ms/step - loss: 0.0017 - accuracy: 0.0017\n",
            "Epoch 87/100\n",
            "38/38 [==============================] - 5s 132ms/step - loss: 0.0017 - accuracy: 0.0017\n",
            "Epoch 88/100\n",
            "38/38 [==============================] - 6s 154ms/step - loss: 0.0017 - accuracy: 0.0017\n",
            "Epoch 89/100\n",
            "38/38 [==============================] - 5s 139ms/step - loss: 0.0018 - accuracy: 0.0017\n",
            "Epoch 90/100\n",
            "38/38 [==============================] - 5s 133ms/step - loss: 0.0016 - accuracy: 0.0017\n",
            "Epoch 91/100\n",
            "38/38 [==============================] - 6s 164ms/step - loss: 0.0015 - accuracy: 0.0017\n",
            "Epoch 92/100\n",
            "38/38 [==============================] - 5s 131ms/step - loss: 0.0016 - accuracy: 0.0017\n",
            "Epoch 93/100\n",
            "38/38 [==============================] - 6s 164ms/step - loss: 0.0016 - accuracy: 0.0017\n",
            "Epoch 94/100\n",
            "38/38 [==============================] - 5s 135ms/step - loss: 0.0014 - accuracy: 0.0017\n",
            "Epoch 95/100\n",
            "38/38 [==============================] - 6s 147ms/step - loss: 0.0014 - accuracy: 0.0017\n",
            "Epoch 96/100\n",
            "38/38 [==============================] - 6s 147ms/step - loss: 0.0015 - accuracy: 0.0017\n",
            "Epoch 97/100\n",
            "38/38 [==============================] - 5s 131ms/step - loss: 0.0015 - accuracy: 0.0017\n",
            "Epoch 98/100\n",
            "38/38 [==============================] - 6s 165ms/step - loss: 0.0016 - accuracy: 0.0017\n",
            "Epoch 99/100\n",
            "38/38 [==============================] - 5s 132ms/step - loss: 0.0014 - accuracy: 0.0017\n",
            "Epoch 100/100\n",
            "38/38 [==============================] - 6s 164ms/step - loss: 0.0013 - accuracy: 0.0017\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ce91caeb880>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the real stock price of 2017\n",
        "\n",
        "dataset_test = pd.read_csv('Google_Stock_Price_Test.csv')\n",
        "real_stock_price = dataset_test.iloc[:, 1:2].values\n",
        "\n",
        "# Getting the predicted stock price of 2017\n",
        "dataset_total = pd.concat((data['Open'], dataset_test['Open']), axis = 0)\n",
        "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
        "inputs = inputs.reshape(-1,1)\n",
        "inputs = sc.transform(inputs)\n",
        "X_test = []\n",
        "for i in range(60, 80):\n",
        "    X_test.append(inputs[i-60:i, 0])\n",
        "X_test = np.array(X_test)\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "predicted_stock_price = regressor.predict(X_test)\n",
        "predicted_stock_price = sc.inverse_transform(predicted_stock_price)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJhRI3VBNca9",
        "outputId": "49215a6a-cd61-460c-ddf3-2fc29b459696"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predicted_stock_price)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4r80bSwNj2K",
        "outputId": "5df5aaef-8780-487f-f299-e81a011fc71f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[788.8084 ]\n",
            " [785.8884 ]\n",
            " [785.75525]\n",
            " [786.89795]\n",
            " [790.0953 ]\n",
            " [795.9691 ]\n",
            " [801.6473 ]\n",
            " [804.3369 ]\n",
            " [805.0035 ]\n",
            " [804.8146 ]\n",
            " [804.4226 ]\n",
            " [803.94635]\n",
            " [803.56555]\n",
            " [803.9343 ]\n",
            " [804.8348 ]\n",
            " [809.3484 ]\n",
            " [816.35767]\n",
            " [824.10767]\n",
            " [828.699  ]\n",
            " [825.2029 ]]\n"
          ]
        }
      ]
    }
  ]
}